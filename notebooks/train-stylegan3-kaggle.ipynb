{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14701468,"sourceType":"datasetVersion","datasetId":9391907},{"sourceId":14702602,"sourceType":"datasetVersion","datasetId":9392662}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# StyleGAN3 Training — Latent Resonance Spectrograms (Kaggle)\n\nTrain StyleGAN3 on 512x512 grayscale spectrogram images.\n\n**Setup:** In the Kaggle sidebar, go to **Settings → Accelerator → GPU T4 x2**.\n\n**Dataset:** Upload your `spectrograms.zip` as a [Kaggle Dataset](https://www.kaggle.com/datasets),\nthen add it to this notebook via **Add data** in the sidebar.","metadata":{}},{"cell_type":"markdown","source":"## 1. Setup & GPU Check","metadata":{}},{"cell_type":"code","source":"!nvidia-smi\n!pip install -q ninja\n\nimport torch\nassert torch.cuda.is_available(), \"No GPU — enable it in Settings → Accelerator → GPU T4 x2\"\nprint(f\"PyTorch {torch.__version__}, CUDA {torch.version.cuda}, GPU: {torch.cuda.get_device_name(0)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:01:08.769104Z","iopub.execute_input":"2026-02-02T19:01:08.769955Z","iopub.status.idle":"2026-02-02T19:01:13.466813Z","shell.execute_reply.started":"2026-02-02T19:01:08.769922Z","shell.execute_reply":"2026-02-02T19:01:13.466047Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Clone StyleGAN3 & Apply Patches","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport pathlib\nimport shutil\nimport subprocess\n\n# Fresh clone\nif os.path.exists(\"stylegan3\"):\n    shutil.rmtree(\"stylegan3\")\n!git clone https://github.com/NVlabs/stylegan3.git\nsys.path.insert(0, \"stylegan3\")\n\n# ── Patch 1: Fix InfiniteSampler for PyTorch ≥2.4 ────────────────────────\nmisc_path = pathlib.Path(\"stylegan3/torch_utils/misc.py\")\nsrc = misc_path.read_text()\nsrc = src.replace(\"super().__init__(dataset)\", \"super().__init__()\")\nmisc_path.write_text(src)\nprint(f\"Patched {misc_path}: InfiniteSampler fix\")\n\n# ── Patch 2: Shape mismatch grayscale and RGB ────────────────\nlines = src.split('\\n')\nnew_lines = []\npatched = False\nfor line in lines:\n    if 'tensor.copy_(src_tensors[name].detach())' in line and not patched:\n        indent = line[:len(line) - len(line.lstrip())]\n        new_lines.append(f'{indent}if src_tensors[name].shape != tensor.shape:')\n        new_lines.append(f'{indent}    continue')\n        new_lines.append(line)\n        patched = True\n    else:\n        new_lines.append(line)\nsrc = '\\n'.join(new_lines)\nassert patched, \"ERROR: could not patch copy_params_and_buffers\"\nprint(f\"  Patch 2: shape-mismatch guard {'applied' if patched else 'FAILED'}\")\n\nmisc_path.write_text(src)\nprint(f\"Patched {misc_path}\")\n\n# ── Patch 3: Fix Adam betas int → float for PyTorch ≥2.9 ────────────────\ntrain_path = pathlib.Path(\"stylegan3/train.py\")\nsrc = train_path.read_text()\nsrc = src.replace(\"betas=[0,0.99]\", \"betas=[0.0,0.99]\")\ntrain_path.write_text(src)\nprint(f\"Patched {train_path}: Adam betas fix\")\n\n# ── Patch 4: Try CUDA ops compilation ────────────────────────────────────\n# Detect GPU compute capability automatically\ncc_major, cc_minor = torch.cuda.get_device_capability(0)\narch = f\"{cc_major}.{cc_minor}\"\nos.environ[\"TORCH_CUDA_ARCH_LIST\"] = arch\nos.environ[\"TORCH_EXTENSIONS_DIR\"] = \"/tmp/torch_extensions\"\nif os.path.exists(\"/tmp/torch_extensions\"):\n    shutil.rmtree(\"/tmp/torch_extensions\")\n\nresult = subprocess.run(\n    [\"python\", \"-c\",\n     \"import sys; sys.path.insert(0,'stylegan3'); \"\n     \"from torch_utils.ops import bias_act; \"\n     \"assert bias_act._init(), 'init failed'\"],\n    capture_output=True, text=True, timeout=180,\n)\n\nCUDA_OPS_OK = result.returncode == 0\nif CUDA_OPS_OK:\n    print(f\"Custom CUDA ops compiled for sm_{cc_major}{cc_minor} — using fused kernels\")\nelse:\n    print(f\"CUDA ops compilation failed (arch {arch}), using native PyTorch fallback\")\n    print(f\"  Error: ...{result.stderr[-300:]}\")\n    ops_dir = pathlib.Path(\"stylegan3/torch_utils/ops\")\n    for name in [\"bias_act.py\", \"upfirdn2d.py\", \"filtered_lrelu.py\"]:\n        p = ops_dir / name\n        s = p.read_text()\n        s = s.replace(\"def _init():\", \"def _init():\\n    return False\")\n        p.write_text(s)\n        print(f\"  Patched {p}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:15:28.702944Z","iopub.execute_input":"2026-02-02T19:15:28.703257Z","iopub.status.idle":"2026-02-02T19:15:51.465849Z","shell.execute_reply.started":"2026-02-02T19:15:28.703228Z","shell.execute_reply":"2026-02-02T19:15:51.464905Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Load Dataset\n\nKaggle datasets are mounted at `/kaggle/input/<dataset-name>/`.\n\nSet `KAGGLE_DATASET` to match your dataset name.","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport shutil\n\nKAGGLE_DATASET = \"spectrograms\"  # <-- your Kaggle dataset name\n\ninput_dir = f\"/kaggle/input/{KAGGLE_DATASET}\"\n\n# Find PNGs (may be in root or a subfolder)\npngs = glob.glob(f\"{input_dir}/**/*.png\", recursive=True)\n\n# Copy to a writable working directory (Kaggle input is read-only)\nDATASET_PATH = \"/kaggle/working/spectrograms\"\nos.makedirs(DATASET_PATH, exist_ok=True)\nfor p in pngs:\n    shutil.copy(p, DATASET_PATH)\n\nprint(f\"Found {len(pngs)} PNG files → copied to {DATASET_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:01:43.938357Z","iopub.execute_input":"2026-02-02T19:01:43.938703Z","iopub.status.idle":"2026-02-02T19:01:47.214571Z","shell.execute_reply.started":"2026-02-02T19:01:43.938676Z","shell.execute_reply":"2026-02-02T19:01:47.213922Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Prepare Dataset","metadata":{}},{"cell_type":"code","source":"!python stylegan3/dataset_tool.py \\\n    --source={DATASET_PATH} \\\n    --dest=./spectrograms.zip \\\n    --resolution=512x512","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:01:53.593421Z","iopub.execute_input":"2026-02-02T19:01:53.593725Z","iopub.status.idle":"2026-02-02T19:01:58.564049Z","shell.execute_reply.started":"2026-02-02T19:01:53.593699Z","shell.execute_reply":"2026-02-02T19:01:58.563408Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Configure Training","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_ALLOC_CONF\"] = \"expandable_segments:True\"\n\nGPUS = 2\nGAMMA = 2.0\nSNAP = 10\nKIMG = 400\nCFG = \"stylegan2\"\nMIRROR = False\nMETRICS = \"none\"\nAUG= \"ada\"\nRESUME = \"https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan2/versions/1/files/stylegan2-ffhq-512x512.pkl\"\n# RESUME = \"\"\nif CUDA_OPS_OK:\n    BATCH_SIZE = 16\n    CBASE = 16384\n    CMAX = 512\n    MBSTD = 8\n    print(f\"CUDA ops available — batch={BATCH_SIZE}, full model capacity\")\nelse:\n    BATCH_SIZE = 2\n    CBASE = 8192\n    CMAX = 128\n    MBSTD = 2\n    print(f\"Native fallback — batch={BATCH_SIZE}, cbase={CBASE}, cmax={CMAX}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:27:45.991475Z","iopub.execute_input":"2026-02-02T19:27:45.992099Z","iopub.status.idle":"2026-02-02T19:27:45.997638Z","shell.execute_reply.started":"2026-02-02T19:27:45.992067Z","shell.execute_reply":"2026-02-02T19:27:45.997001Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Train","metadata":{}},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n\nresume_flag = f\"--resume={RESUME}\" if RESUME else \"\"\nmirror_int = 1 if MIRROR else 0\n\n!python stylegan3/train.py \\\n    --outdir=./training-runs \\\n    --cfg={CFG} \\\n    --data=./spectrograms.zip \\\n    --gpus={GPUS} \\\n    --batch={BATCH_SIZE} \\\n    --batch-gpu={int(BATCH_SIZE / GPUS)} \\\n    --gamma={GAMMA} \\\n    --snap={SNAP} \\\n    --kimg={KIMG} \\\n    --mirror={mirror_int} \\\n    --metrics={METRICS} \\\n    --cbase={CBASE} \\\n    --cmax={CMAX} \\\n    --mbstd-group={MBSTD} \\\n    --aug={AUG}\\\n    {resume_flag}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:27:48.757572Z","iopub.execute_input":"2026-02-02T19:27:48.758078Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Generate Samples","metadata":{}},{"cell_type":"code","source":"import glob\nimport pickle\n\nimport matplotlib.pyplot as plt\nimport torch\n\npkls = sorted(glob.glob(\"training-runs/**/*.pkl\", recursive=True))\nassert pkls, \"No snapshots found — has training completed at least one snapshot?\"\nlatest_pkl = pkls[-1]\nprint(f\"Loading {latest_pkl}\")\n\nwith open(latest_pkl, \"rb\") as f:\n    G = pickle.load(f)[\"G_ema\"].cuda().eval()\n\nz = torch.randn(4, G.z_dim, device=\"cuda\")\nwith torch.no_grad():\n    imgs = G(z, None)\n\nfig, axes = plt.subplots(1, 4, figsize=(16, 4))\nfor i, ax in enumerate(axes):\n    img = imgs[i, 0].cpu().numpy()\n    ax.imshow(img, cmap=\"magma\", aspect=\"auto\")\n    ax.set_title(f\"Sample {i}\")\n    ax.axis(\"off\")\nplt.suptitle(\"Generated Spectrograms\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T02:47:28.838622Z","iopub.execute_input":"2026-02-02T02:47:28.83925Z","iopub.status.idle":"2026-02-02T02:47:31.732632Z","shell.execute_reply.started":"2026-02-02T02:47:28.839216Z","shell.execute_reply":"2026-02-02T02:47:31.731907Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8. Save Results\n\nKaggle persists everything in `/kaggle/working/` as notebook output.\nClick **Save Version** (top right) → the training-runs zip will be available under **Output**.","metadata":{}},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\"/kaggle/working/training-runs\", \"zip\", \".\", \"training-runs\")\nprint(\"Created /kaggle/working/training-runs.zip\")\nprint(\"This will be saved as notebook output when you click Save Version.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"  !ls -la training-runs/                                                                                                   ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}