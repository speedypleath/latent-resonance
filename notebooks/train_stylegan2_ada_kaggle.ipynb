{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StyleGAN2-ADA Training — Latent Resonance Spectrograms (Kaggle)\n",
    "\n",
    "Train StyleGAN2-ADA on 512×512 grayscale spectrogram images.\n",
    "ADA (Adaptive Discriminator Augmentation) is purpose-built for limited-data regimes,\n",
    "making it a better fit than StyleGAN3 for small datasets (435–489 images).\n",
    "\n",
    "**Setup:** In the Kaggle sidebar, go to **Settings → Accelerator → GPU T4 x2**.\n",
    "\n",
    "**Dataset:** Upload your `spectrograms.zip` as a [Kaggle Dataset](https://www.kaggle.com/datasets),\n",
    "then add it to this notebook via **Add data** in the sidebar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "!pip install -q ninja\n",
    "\n",
    "import torch\n",
    "assert torch.cuda.is_available(), \"No GPU — enable it in Settings → Accelerator → GPU T4 x2\"\n",
    "print(f\"PyTorch {torch.__version__}, CUDA {torch.version.cuda}, GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone StyleGAN2-ADA & Apply Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "# Fresh clone\n",
    "if os.path.exists(\"stylegan2-ada-pytorch\"):\n",
    "    shutil.rmtree(\"stylegan2-ada-pytorch\")\n",
    "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git\n",
    "sys.path.insert(0, \"stylegan2-ada-pytorch\")\n",
    "\n",
    "# ── Patch 1: Fix InfiniteSampler for PyTorch ≥2.4 ────────────────────────\n",
    "misc_path = pathlib.Path(\"stylegan2-ada-pytorch/torch_utils/misc.py\")\n",
    "src = misc_path.read_text()\n",
    "src = src.replace(\"super().__init__(dataset)\", \"super().__init__()\")\n",
    "misc_path.write_text(src)\n",
    "print(f\"Patched {misc_path}: InfiniteSampler fix\")\n",
    "\n",
    "# ── Patch 2: Fix Adam betas int → float for PyTorch ≥2.9 ────────────────\n",
    "train_path = pathlib.Path(\"stylegan2-ada-pytorch/train.py\")\n",
    "src = train_path.read_text()\n",
    "src = src.replace(\"betas=[0,0.99]\", \"betas=[0.0,0.99]\")\n",
    "train_path.write_text(src)\n",
    "print(f\"Patched {train_path}: Adam betas fix\")\n",
    "\n",
    "# ── Patch 3: Try CUDA ops compilation ────────────────────────────────────\n",
    "cc_major, cc_minor = torch.cuda.get_device_capability(0)\n",
    "arch = f\"{cc_major}.{cc_minor}\"\n",
    "os.environ[\"TORCH_CUDA_ARCH_LIST\"] = arch\n",
    "os.environ[\"TORCH_EXTENSIONS_DIR\"] = \"/tmp/torch_extensions\"\n",
    "if os.path.exists(\"/tmp/torch_extensions\"):\n",
    "    shutil.rmtree(\"/tmp/torch_extensions\")\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"python\", \"-c\",\n",
    "     \"import sys; sys.path.insert(0,'stylegan2-ada-pytorch'); \"\n",
    "     \"from torch_utils.ops import bias_act; \"\n",
    "     \"assert bias_act._init(), 'init failed'\"],\n",
    "    capture_output=True, text=True, timeout=180,\n",
    ")\n",
    "\n",
    "CUDA_OPS_OK = result.returncode == 0\n",
    "if CUDA_OPS_OK:\n",
    "    print(f\"Custom CUDA ops compiled for sm_{cc_major}{cc_minor} — using fused kernels\")\n",
    "else:\n",
    "    print(f\"CUDA ops compilation failed (arch {arch}), using native PyTorch fallback\")\n",
    "    print(f\"  Error: ...{result.stderr[-300:]}\")\n",
    "    ops_dir = pathlib.Path(\"stylegan2-ada-pytorch/torch_utils/ops\")\n",
    "    for name in [\"bias_act.py\", \"upfirdn2d.py\"]:\n",
    "        p = ops_dir / name\n",
    "        s = p.read_text()\n",
    "        s = s.replace(\"def _init():\", \"def _init():\\n    return False\")\n",
    "        p.write_text(s)\n",
    "        print(f\"  Patched {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Dataset\n",
    "\n",
    "Kaggle datasets are mounted at `/kaggle/input/<dataset-name>/`.\n",
    "\n",
    "Set `KAGGLE_DATASET` to match your dataset name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "KAGGLE_DATASET = \"spectrograms\"  # <-- your Kaggle dataset name\n",
    "\n",
    "input_dir = f\"/kaggle/input/{KAGGLE_DATASET}\"\n",
    "\n",
    "# Find PNGs (may be in root or a subfolder)\n",
    "pngs = glob.glob(f\"{input_dir}/**/*.png\", recursive=True)\n",
    "\n",
    "# Copy to a writable working directory (Kaggle input is read-only)\n",
    "DATASET_PATH = \"/kaggle/working/spectrograms\"\n",
    "os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "for p in pngs:\n",
    "    shutil.copy(p, DATASET_PATH)\n",
    "\n",
    "print(f\"Found {len(pngs)} PNG files → copied to {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python stylegan2-ada-pytorch/dataset_tool.py \\\n",
    "    --source={DATASET_PATH} \\\n",
    "    --dest=./spectrograms.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "GPUS = 1              # single GPU more stable for small datasets\n",
    "GAMMA = 10.0          # higher R1 regularization for small datasets\n",
    "SNAP = 10\n",
    "KIMG = 5000\n",
    "AUG = \"ada\"           # adaptive discriminator augmentation\n",
    "TARGET = 0.6          # ADA target heuristic — good default for small datasets\n",
    "MIRROR = False\n",
    "METRICS = \"none\"\n",
    "BATCH_SIZE = 8\n",
    "RESUME = \"\"\n",
    "\n",
    "print(f\"Config: gpus={GPUS}, batch={BATCH_SIZE}, gamma={GAMMA}, aug={AUG}, target={TARGET}, mirror={MIRROR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "resume_flag = f\"--resume={RESUME}\" if RESUME else \"\"\n",
    "mirror_int = 1 if MIRROR else 0\n",
    "\n",
    "!python stylegan2-ada-pytorch/train.py \\\n",
    "    --outdir=./training-runs \\\n",
    "    --cfg=auto \\\n",
    "    --data=./spectrograms.zip \\\n",
    "    --gpus={GPUS} \\\n",
    "    --batch={BATCH_SIZE} \\\n",
    "    --gamma={GAMMA} \\\n",
    "    --snap={SNAP} \\\n",
    "    --kimg={KIMG} \\\n",
    "    --aug={AUG} \\\n",
    "    --target={TARGET} \\\n",
    "    --mirror={mirror_int} \\\n",
    "    --metrics={METRICS} \\\n",
    "    {resume_flag}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "pkls = sorted(glob.glob(\"training-runs/**/*.pkl\", recursive=True))\n",
    "assert pkls, \"No snapshots found — has training completed at least one snapshot?\"\n",
    "latest_pkl = pkls[-1]\n",
    "print(f\"Loading {latest_pkl}\")\n",
    "\n",
    "with open(latest_pkl, \"rb\") as f:\n",
    "    G = pickle.load(f)[\"G_ema\"].cuda().eval()\n",
    "\n",
    "z = torch.randn(4, G.z_dim, device=\"cuda\")\n",
    "with torch.no_grad():\n",
    "    imgs = G(z, None)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "for i, ax in enumerate(axes):\n",
    "    img = imgs[i, 0].cpu().numpy()\n",
    "    ax.imshow(img, cmap=\"magma\", aspect=\"auto\")\n",
    "    ax.set_title(f\"Sample {i}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(\"Generated Spectrograms (StyleGAN2-ADA)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results\n",
    "\n",
    "Kaggle persists everything in `/kaggle/working/` as notebook output.\n",
    "Click **Save Version** (top right) → the training-runs zip will be available under **Output**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(\"/kaggle/working/training-runs\", \"zip\", \".\", \"training-runs\")\n",
    "print(\"Created /kaggle/working/training-runs.zip\")\n",
    "print(\"This will be saved as notebook output when you click Save Version.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
